{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from Disk and Calculate Collab Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = spark.read.parquet(\"Data/authors-cat:stat.ML.parquet\")\n",
    "collab_df = spark.read.parquet(\"Data/collab-cat:stat.ML.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = 2 and id = 90\n",
    "# author1 = 2\n",
    "# author2 = 3338\n",
    "# depth_max = 10\n",
    "\n",
    "def collab_dist(author1, author2, depth_max = 10):\n",
    "    \n",
    "    # BFS\n",
    "    fifo = queue.Queue()\n",
    "    fifo.put(author1)\n",
    "\n",
    "    # To track depth to stop search at max depth\n",
    "    depth = queue.Queue()\n",
    "    depth.put(0)\n",
    "\n",
    "    # To find depth and the path backwards\n",
    "    parents = {author1 : -1}\n",
    "\n",
    "    while not fifo.empty():\n",
    "        a = fifo.get() ; d = depth.get()\n",
    "        print(\"AuthorID:\", a)\n",
    "        if a == author2:\n",
    "            break\n",
    "\n",
    "        if d >= depth_max:\n",
    "            print(\"Max depth of %i is reached.\" % d)\n",
    "            break\n",
    "\n",
    "        # \"src\" in collab item is equal to author1, look for the authors in \"dest\"\n",
    "        df_dest = collab_df.filter(collab_df.src == a).select(collab_df.columns[1])\n",
    "        for i in [int(row.dest) for row in df_dest.collect()]:\n",
    "            print(\"Next author: %i\" % i)\n",
    "            if i not in parents: #if already visited, don't add the queue\n",
    "                fifo.put(i); depth.put(d + 1)\n",
    "                parents[i] = a\n",
    "\n",
    "        # \"dest\" in collab item is equal to author1, look for the authors in \"src\"\n",
    "        df_src = collab_df.filter(collab_df.dest == a).select(collab_df.columns[0])\n",
    "        for i in [int(row.src) for row in df_src.collect()]:\n",
    "            print(\"Next author: %i\" % i)\n",
    "            if i not in parents:\n",
    "                fifo.put(i); depth.put(d + 1)\n",
    "                parents[i] = a\n",
    "\n",
    "    # Calculate the depth.\n",
    "    dist = 0           \n",
    "    while parents[a] > 0:\n",
    "        dist = dist + 1\n",
    "        a = parents[a]\n",
    "    \n",
    "    return (dist, d, parents)\n",
    "    \n",
    "\n",
    "# print(\"Parents: %s\" % parents)\n",
    "# print(\"Dist:\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorID: 2\n",
      "Next author: 1\n",
      "Next author: 3338\n",
      "Next author: 671\n",
      "AuthorID: 1\n",
      "Next author: 2\n",
      "Next author: 215\n",
      "Next author: 700\n",
      "AuthorID: 3338\n",
      "Next author: 671\n",
      "Next author: 2\n",
      "AuthorID: 671\n",
      "Next author: 2\n",
      "Next author: 3338\n",
      "AuthorID: 215\n",
      "Next author: 216\n",
      "Next author: 217\n",
      "Next author: 881\n",
      "Next author: 1465\n",
      "Next author: 231\n",
      "Next author: 1465\n",
      "Next author: 3204\n",
      "Next author: 3484\n",
      "Next author: 145\n",
      "Next author: 700\n",
      "Next author: 701\n",
      "Next author: 217\n",
      "Next author: 701\n",
      "Next author: 549\n",
      "Next author: 231\n",
      "Next author: 847\n",
      "Next author: 270\n",
      "Next author: 85\n",
      "Next author: 880\n",
      "Next author: 549\n",
      "Next author: 231\n",
      "Next author: 85\n",
      "Next author: 1464\n",
      "Next author: 700\n",
      "Next author: 1\n",
      "Next author: 549\n",
      "Next author: 549\n",
      "Next author: 2113\n",
      "Next author: 231\n",
      "Next author: 1464\n",
      "Next author: 1175\n",
      "Next author: 239\n",
      "Next author: 2952\n",
      "Next author: 2953\n",
      "Next author: 740\n",
      "Next author: 863\n",
      "Next author: 2979\n",
      "Next author: 700\n",
      "Next author: 414\n",
      "Next author: 889\n",
      "AuthorID: 700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 2,\n",
       " {2: -1,\n",
       "  1: 2,\n",
       "  3338: 2,\n",
       "  671: 2,\n",
       "  215: 1,\n",
       "  700: 1,\n",
       "  216: 215,\n",
       "  217: 215,\n",
       "  881: 215,\n",
       "  1465: 215,\n",
       "  231: 215,\n",
       "  3204: 215,\n",
       "  3484: 215,\n",
       "  145: 215,\n",
       "  701: 215,\n",
       "  549: 215,\n",
       "  847: 215,\n",
       "  270: 215,\n",
       "  85: 215,\n",
       "  880: 215,\n",
       "  1464: 215,\n",
       "  2113: 215,\n",
       "  1175: 215,\n",
       "  239: 215,\n",
       "  2952: 215,\n",
       "  2953: 215,\n",
       "  740: 215,\n",
       "  863: 215,\n",
       "  2979: 215,\n",
       "  414: 215,\n",
       "  889: 215})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_dist(2,700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3338"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_dest = collab_df.filter(collab_df.dest == 2).select(collab_df.columns[0]).collect()\n",
    "collab_dest[1].src\n",
    "[int(row.mvv) for row in mvv_list.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_df.filter(collab_df.src == 2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dest = collab_df.filter(collab_df.src == a).select(collab_df.columns[1])\n",
    "[int(row.src) for row in df_dest.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
