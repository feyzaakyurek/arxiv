{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data from Disk and Calculate Collab Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "import queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_df = spark.read.parquet(\"Data/authors-catstat.ML+OR+catstat.AP+OR+catstat.CO+OR+catstat.ME+OR+catstat.OT+OR+catstat.TH-total49904.parquet\")\n",
    "collab_df = spark.read.parquet(\"Data/collab-catstat.ML+OR+catstat.AP+OR+catstat.CO+OR+catstat.ME+OR+catstat.OT+OR+catstat.TH-total49904.parquet\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id = 2 and id = 90\n",
    "# author1 = 2\n",
    "# author2 = 3338\n",
    "# depth_max = 10\n",
    "\n",
    "def collab_dist(author1, author2, depth_max = 3):\n",
    "    \n",
    "    # BFS\n",
    "    fifo = queue.Queue()\n",
    "    fifo.put(author1)\n",
    "\n",
    "    # To track depth to stop search at max depth\n",
    "    depth = queue.Queue()\n",
    "    depth.put(0)\n",
    "\n",
    "    # To find depth and the path backwards\n",
    "    parents = {author1 : -1}\n",
    "    i = 0\n",
    "    while not fifo.empty():\n",
    "        a = fifo.get() ; d = depth.get()\n",
    "#         print(\"AuthorID:\", a)\n",
    "        if a == author2:\n",
    "            break\n",
    "\n",
    "        if d > depth_max:\n",
    "            print(\"Max depth of %i is reached.\" % d)\n",
    "            break\n",
    "\n",
    "        # \"src\" in collab item is equal to author1, look for the authors in \"dest\"\n",
    "        df_dest = collab_df.filter(collab_df.src == a).select(collab_df.columns[1])\n",
    "        for i in [int(row.dest) for row in df_dest.collect()]:\n",
    "#             print(\"Next author: %i\" % i)\n",
    "            if i not in parents: #if already visited, don't add the queue\n",
    "                fifo.put(i); depth.put(d + 1)\n",
    "                parents[i] = a\n",
    "\n",
    "        # \"dest\" in collab item is equal to author1, look for the authors in \"src\"\n",
    "        df_src = collab_df.filter(collab_df.dest == a).select(collab_df.columns[0])\n",
    "        for i in [int(row.src) for row in df_src.collect()]:\n",
    "#             print(\"Next author: %i\" % i)\n",
    "            if i not in parents:\n",
    "                fifo.put(i); depth.put(d + 1)\n",
    "                parents[i] = a\n",
    "        i = i + 1\n",
    "        if i == 1000: break\n",
    "    # Calculate the depth.\n",
    "    dist = 0\n",
    "    ancestry = [a]\n",
    "    while parents[a] > 0:\n",
    "        dist = dist + 1\n",
    "        a = parents[a]\n",
    "        ancestry.append(a)\n",
    "    return (dist, d, ancestry, parents)\n",
    "    \n",
    "\n",
    "# print(\"Parents: %s\" % parents)\n",
    "# print(\"Dist:\", dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, d, ancestry, parents = collab_dist(323,352,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[352, 1260, 323]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist\n",
    "ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alex 6896\n",
    "Ale 352\n",
    "Joel 15622\n",
    "Peter 1690\n",
    "Daren Wang 6212\n",
    "Kayvan 350\n",
    "Addison 23894\n",
    "Martin 323\n",
    "Peter - Larry - Ale - Kayvan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = author_df.where(author_df.name == \"Martin J. Wainwright\").select(\"id\")\n",
    "r.rdd.map(lambda x: x.id).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1260, name='Aaditya Ramdas')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.filter(author_df.id == 1260).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=6896, name='Alex Reinhart')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_df.filter(author_df.name == \"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3338"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_dest = collab_df.filter(collab_df.dest == 2).select(collab_df.columns[0]).collect()\n",
    "collab_dest[1].src\n",
    "[int(row.mvv) for row in mvv_list.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src=23894, dest=23401, arxiv='1710.07006v1', title='Minimax Estimation of Bandable Precision Matrices')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_df.filter((collab_df.src == 23894) | (collab_df.dest == 23894)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dest = collab_df.filter(collab_df.src == a).select(collab_df.columns[1])\n",
    "[int(row.src) for row in df_dest.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(src=1557, dest=1555, arxiv='1406.7536v1', title='Estimating the distribution of Galaxy Morphologies on a continuous space')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_df.filter(collab_df.src == 1557).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
